{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8de4634a-71f5-4c45-8c91-a938718c5aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "import time\n",
    "import multiprocessing\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, DistributedSampler\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import subprocess\n",
    "import torch.multiprocessing as mp\n",
    "import torch.optim as optim\n",
    "import torch.distributed as dist\n",
    "from multiprocessing import Process, Manager, set_start_method\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d311a9d1-5848-43ff-a424-06211accf93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 1 workers...\n"
     ]
    }
   ],
   "source": [
    "#Using Multiprocessing\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(32 * 64 * 64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "def get_data_loader(batch_size=32):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    train_set = datasets.ImageFolder(root='Food Classification dataset/train', transform=transform)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    return train_loader\n",
    "\n",
    "def train_process(rank, model, train_loader, criterion, optimizer, device):\n",
    "    torch.set_num_threads(1)\n",
    "    model.to(device)\n",
    "    total_correct = 0\n",
    "    total_images = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_images += labels.size(0)\n",
    "\n",
    "    accuracy = total_correct / total_images\n",
    "    return accuracy\n",
    "\n",
    "def train_parallel(num_workers):\n",
    "    batch_size = 32\n",
    "    model = SimpleCNN()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    train_loader = get_data_loader(batch_size=batch_size)\n",
    "\n",
    "    dataset_size = len(train_loader.dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = dataset_size // num_workers\n",
    "    subsets = [indices[i * split: (i + 1) * split] for i in range(num_workers)]\n",
    "    loaders = [DataLoader(Subset(train_loader.dataset, subset), batch_size=batch_size, shuffle=True) for subset in subsets]\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Using multiprocessing\n",
    "    with multiprocessing.Pool(processes=num_workers) as pool:\n",
    "        results = pool.starmap(train_process, [(i, model, loaders[i], criterion, optimizer, torch.device('cpu')) for i in range(num_workers)])\n",
    "\n",
    "    time_taken = time.time() - start_time\n",
    "    average_accuracy = sum(results) / num_workers\n",
    "\n",
    "    return time_taken, average_accuracy\n",
    "\n",
    "def main():\n",
    "    worker_configs = [1, 2, 4, 8, 16]\n",
    "    training_times = []\n",
    "    accuracies = []\n",
    "    for workers in worker_configs:\n",
    "        print(f\"Training with {workers} workers...\")\n",
    "        start_time = time.time()\n",
    "        time_taken, accuracy = train_parallel(workers)\n",
    "        training_times.append(time_taken)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"Training completed in {time_taken:.2f} seconds with accuracy {accuracy * 100:.2f}% using {workers} workers.\")\n",
    "\n",
    "    # Calculate speedups and efficiencies\n",
    "    base_time = training_times[0]\n",
    "    speedups = [base_time / time for time in training_times]\n",
    "    efficiencies = [speedup / workers for speedup, workers in zip(speedups, worker_configs)]\n",
    "\n",
    "    # Plot the metrics\n",
    "    plot_training_times(worker_configs, training_times, accuracies, speedups, efficiencies)\n",
    "\n",
    "def plot_training_times(worker_configs, training_times, accuracies, speedups, efficiencies):\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(worker_configs, training_times, marker='o')\n",
    "    plt.title('Training Time vs. Number of Workers')\n",
    "    plt.xlabel('Number of Workers')\n",
    "    plt.ylabel('Training Time (seconds)')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(worker_configs, [acc * 100 for acc in accuracies], marker='o')\n",
    "    plt.title('Accuracy vs. Number of Workers')\n",
    "    plt.xlabel('Number of Workers')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(worker_configs, speedups, marker='o')\n",
    "    plt.title('Speedup vs. Number of Workers')\n",
    "    plt.xlabel('Number of Workers')\n",
    "    plt.ylabel('Speedup')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(worker_configs, efficiencies, marker='o')\n",
    "    plt.title('Efficiency vs. Number of Workers')\n",
    "    plt.xlabel('Number of Workers')\n",
    "    plt.ylabel('Efficiency')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fcb5d1-703e-426c-94ef-472d2eda569e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
